# 2026-01-19 Daily Log

## Projects
Continued [[nacre]] architecture work. Designed the **decay model** in detail — an **Ebbinghaus**-inspired forgetting curve where edge weights decay exponentially over time unless reinforced. The formula: weight = W₀ · e^(-λt/S) where S is a stability factor that grows with reinforcement.

**Marcus** and I discussed the decay parameters over a call. He asked the right question: "how do you know the decay rate is correct?" This led to designing an experimental framework with five configurations — no decay, gentle, target, aggressive, and target without thresholds.

[[kelp]] needs attention — **Quinn** flagged that the data pipeline is dropping records during peak load. Looks like a backpressure issue.

## Architecture
The **co-occurrence threshold** is important. Two entities appearing in the same section once might be coincidence. But if they appear together across multiple files, that is a real signal. Default threshold: 2 observations before creating an edge. This prevents the graph from becoming a hairball of noise connections. #architecture

Pending edges track sub-threshold co-occurrences. When count reaches the threshold, the pending edge graduates to a real edge in the graph.

## Tools
Using **Claude Code** for architecture review — rubber ducking the decay math and getting sanity checks on the formulas. Also using `Node.js` test runner (`node --test`) for the core package tests.

## Lessons
**Forgetting is a feature, not a bug** — a knowledge graph that remembers everything equally is useless. The whole point of decay is to let important connections stand out by fading the noise. This resulted in a much cleaner graph design.
